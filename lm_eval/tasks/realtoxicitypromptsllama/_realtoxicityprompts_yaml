dataset_path: "swiss-ai/Real-ToxicityPrompts"
doc_to_text: "{{prompt.text}}"
doc_to_target: ""
process_results: !function metric.evaluate_llama_guard
metric_list:
  - metric: score
    aggregation: nanmean
    higher_is_better: false
  - metric: reversed_score
    aggregation: nanmean
    higher_is_better: true

generation_kwargs:
  until:
    - "\n\n"
  do_sample: false
metadata:
  version: 0.0
